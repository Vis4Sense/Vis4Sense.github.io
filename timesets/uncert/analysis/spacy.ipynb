{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Named Entities Extraction with spacy\n",
    "*This is to explore spacy, particularly for extracting named entities in facebook dataset for TimeSets paper.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To install the library and the required trained models:\n",
    "\n",
    "```\n",
    "pip install spacy\n",
    "python -m spacy download en\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_file = '../data/fbv4.json'\n",
    "output_file = '../data/facebook-with-themes.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import itertools\n",
    "from collections import Counter\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_post(post):\n",
    "    time = post.get('created_time')\n",
    "    subject = post.get('Subject', '').strip()\n",
    "    content = post.get('description', '').strip()\n",
    "    text = (subject + '. ' + content).strip()\n",
    "    trust = post.get('Trust', '')\n",
    "    relevance = post.get('Relevance', '')\n",
    "\n",
    "    return text, time, subject, content, trust, relevance\n",
    "\n",
    "def load_data(filename):\n",
    "    with open(filename) as f:\n",
    "        posts = json.load(f) # list of posts\n",
    "        posts = [extract_post(post) for post in posts]\n",
    "        return [p for p in posts if p[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(949,\n",
       " ('1 Woman Killed, Several Children Injured in Aleppo.',\n",
       "  '2016-09-19T16:28:44+0000',\n",
       "  '1 Woman Killed, Several Children Injured in Aleppo',\n",
       "  '',\n",
       "  'C3',\n",
       "  4),\n",
       " '1 Woman Killed, Several Children Injured in Aleppo.')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts = load_data(input_file)\n",
    "docs = [p[0] for p in posts]\n",
    "len(posts), posts[0], docs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('CARDINAL', '1'),\n",
       " ('ORG', 'Aleppo..'),\n",
       " ('WORK_OF_ART', \"Journal' Recovered\"),\n",
       " ('NORP', 'Syrian'),\n",
       " ('GPE', 'US'),\n",
       " ('PERSON', 'Man Believed'),\n",
       " ('PERSON', 'Good Morning America'),\n",
       " ('PRODUCT', 'JEB EXCLAMATION'),\n",
       " ('PERSON', 'Jeb Bush'),\n",
       " ('PERSON', 'Selina Meyer')]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entities = [(e.label_, e.text) for e in nlp('. '.join(docs)).ents]\n",
    "entities[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common entities per type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CARDINAL\n",
      "[('one', 14), ('two', 10), ('5', 6), ('One', 6), ('Two', 5)]\n",
      "\n",
      "DATE\n",
      "[('2016', 13), ('Election Day', 6), ('Monday', 5), ('today', 5), ('This Week', 4)]\n",
      "\n",
      "EVENT\n",
      "[('the 2024 Olympics', 2), ('the Iraq War', 2), (\"NYC Bombing 'Act of Terror'\", 1), (\"Between Two Ferns' Interview\", 1), ('Bombing Incidents NY', 1)]\n",
      "\n",
      "FAC\n",
      "[('Blue Point Brewery', 1), ('Latest National Poll', 1), ('Influential San Francisco Activist Rose Pak Dies', 1), ('Times Square', 1), ('â€¦', 1)]\n",
      "\n",
      "GPE\n",
      "[('Charlotte', 31), ('US', 25), ('America', 15), ('North Carolina', 10), ('New York', 9)]\n",
      "\n",
      "LAW\n",
      "[('Thug Videos Cop', 1), ('the Constitution', 1), ('SCREENSHOTS', 1), ('the Midst of a COUP', 1)]\n",
      "\n",
      "LOC\n",
      "[('Strait Talk', 1), ('Mediterranean', 1), ('Nile Delta', 1), ('Northern California', 1), ('Dear America', 1)]\n",
      "\n",
      "MONEY\n",
      "[('Debates', 3), ('Trump', 3), ('$5 million', 3), ('MyVote', 2), ('$1 million', 2)]\n",
      "\n",
      "NORP\n",
      "[('Trump', 16), ('Republicans', 14), ('Democrats', 14), ('Americans', 13), ('Muslim', 8)]\n",
      "\n",
      "ORDINAL\n",
      "[('first', 26), ('First', 8), ('1st', 2), ('second', 2), ('eighth', 1)]\n",
      "\n",
      "ORG\n",
      "[('GOP', 20), (\"Trump's\", 18), ('CNN', 16), ('FBI', 14), ('Trump', 11)]\n",
      "\n",
      "PERCENT\n",
      "[('70%', 2), ('5.7%', 2), ('93%', 1), ('550 percent', 1), ('at least 70%', 1)]\n",
      "\n",
      "PERSON\n",
      "[('Clinton', 116), ('Hillary', 76), ('Hillary Clinton', 60), ('Timeline Photos', 54), ('Donald Trump', 49)]\n",
      "\n",
      "PRODUCT\n",
      "[('JEB EXCLAMATION', 1), ('A Political Conflict Zone', 1), ('Terence Crutcher', 1), ('9/11', 1), ('Create Show Trial', 1)]\n",
      "\n",
      "TIME\n",
      "[('tonight', 8), ('night', 3), (\"About Tonight's\", 2), ('Tonight', 2), ('early this morning', 1)]\n",
      "\n",
      "WORK_OF_ART\n",
      "[('The Impact of Debates', 2), (\"West Wing'\", 2), ('Watered-Down', 2), ('Targeting For Him', 2), ('The Debate', 2)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "entities.sort(key=lambda x: x[0])\n",
    "for k, g in itertools.groupby(entities, lambda x: x[0]):\n",
    "    c = Counter([x[1] for x in g])\n",
    "    print(k)\n",
    "    print(c.most_common(5))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most common entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Clinton', 116),\n",
       " ('Hillary', 76),\n",
       " ('Timeline Photos', 63),\n",
       " ('Hillary Clinton', 60),\n",
       " ('Trump', 53),\n",
       " ('Donald Trump', 49),\n",
       " ('Obama', 44),\n",
       " ('Charlotte', 31),\n",
       " ('first', 26),\n",
       " ('US', 25),\n",
       " ('GOP', 20),\n",
       " (\"Trump's\", 18),\n",
       " ('CNN', 16),\n",
       " ('America', 15),\n",
       " ('one', 14),\n",
       " ('Republicans', 14),\n",
       " ('Democrats', 14),\n",
       " ('FBI', 14),\n",
       " ('2016', 13),\n",
       " ('Americans', 13)]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = Counter(e[1] for e in entities)\n",
    "c.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Clinton\n",
      "1 Hillary\n",
      "2 Timeline Photos\n",
      "3 Hillary Clinton\n",
      "4 Trump\n",
      "5 Donald Trump\n",
      "6 Obama\n",
      "7 Charlotte\n",
      "8 first\n",
      "9 US\n",
      "10 GOP\n",
      "11 Trump's\n",
      "12 CNN\n",
      "13 America\n",
      "14 one\n",
      "15 Republicans\n",
      "16 Democrats\n",
      "17 FBI\n",
      "18 2016\n",
      "19 Americans\n"
     ]
    }
   ],
   "source": [
    "common_entities = [e[0] for e in c.most_common(20)]\n",
    "for i, e in enumerate(common_entities):\n",
    "    print(i, e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Themes for TimeSets\n",
    "Some entities should be merged such as the ones about Trump."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trump\n",
      "Donald Trump\n",
      "Trump's\n"
     ]
    }
   ],
   "source": [
    "print(common_entities[4])\n",
    "print(common_entities[5])\n",
    "print(common_entities[11])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and Cliton."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clinton\n",
      "Hillary\n",
      "Hillary Clinton\n"
     ]
    }
   ],
   "source": [
    "print(common_entities[0])\n",
    "print(common_entities[1])\n",
    "print(common_entities[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, I will define a theme as an array of entities that should be merged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = common_entities\n",
    "theme_indices = [\n",
    "    [0, 1, 3],\n",
    "    [4, 5, 11],\n",
    "    [6],\n",
    "    [7],\n",
    "    [10],\n",
    "    [15],\n",
    "    [16],\n",
    "    [17]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Clinton', 'Hillary', 'Hillary Clinton'],\n",
       " ['Trump', 'Donald Trump', \"Trump's\"],\n",
       " ['Obama'],\n",
       " ['Charlotte'],\n",
       " ['GOP'],\n",
       " ['Republicans'],\n",
       " ['Democrats'],\n",
       " ['FBI']]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "themes = [[common_entities[i] for i in indices] for indices in theme_indices]\n",
    "themes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Clinton',\n",
       " 'Trump',\n",
       " 'Obama',\n",
       " 'Charlotte',\n",
       " 'GOP',\n",
       " 'Republicans',\n",
       " 'Democrats',\n",
       " 'FBI']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theme_labels = [theme[0] for theme in themes]\n",
    "theme_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export data for TimeSets\n",
    "What data format in TimeSets look like?\n",
    "```\n",
    "{\n",
    "    themes: ['theme1', 'theme2'], # array of themes, each as a text\n",
    "    events: [\n",
    "        title,\n",
    "        time,\n",
    "        content,\n",
    "        trust,\n",
    "        relevance,\n",
    "        themes: [] # a subset of the above array of themes\n",
    "    ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_themes(doc, themes, theme_labels):\n",
    "    entities = [(e.label_, e.text) for e in nlp(doc).ents]\n",
    "    entities = [e[1] for e in entities]\n",
    "    \n",
    "    doc_theme_labels = []\n",
    "    for i, theme in enumerate(themes):\n",
    "        if any(e in theme for e in entities): # Check if the document's entities contain any themes\n",
    "            doc_theme_labels.append(theme_labels[i])\n",
    "            \n",
    "    return doc_theme_labels\n",
    "\n",
    "# def get_first_sentence(doc):\n",
    "#     sents = list(nlp(doc).sents)\n",
    "#     return str(sents[0]) if sents else doc\n",
    "\n",
    "def format_data(post, themes, theme_labels):\n",
    "    doc = post[0]\n",
    "    return {\n",
    "        'time': post[1],\n",
    "        'title': post[2],\n",
    "        'content': post[3],\n",
    "        'trust': post[4],\n",
    "        'relevance': post[5],\n",
    "        'themes': get_themes(doc, themes, theme_labels)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(334,\n",
       " {'content': '',\n",
       "  'relevance': 4,\n",
       "  'themes': ['Republicans'],\n",
       "  'time': '2016-09-20T17:08:03+0000',\n",
       "  'title': 'Republicans See Turnaround in Indiana Senate Race',\n",
       "  'trust': 'C3'})"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events = [format_data(post, themes, theme_labels) for post in posts]\n",
    "events = [e for e in events if e['themes']]\n",
    "len(events), events[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = {\n",
    "    'themes': theme_labels,\n",
    "    'events': events\n",
    "}\n",
    "\n",
    "with open(output_file, 'w') as f:\n",
    "    json.dump(data, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "base_numbering": 1.0,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
